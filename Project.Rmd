---
title: "Practical Machine Learning Project"
author: "Mohamed ZAYED"
date: "October, 2015"
output: html_document
---

## Getting Data

* Read both training and testing data. 

```{r}
library(data.table)
library(caret)
library(randomForest)
library(foreach)
library(rpart)
library(rpart.plot)
library(corrplot)
library(dplyr)

set.seed(12345)
if(!file.exists("pml-training.csv"))
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv")
}

if(!file.exists("pml-testing.csv"))
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-testing.csv")
}

training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
testing_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
```

## Cleaning Data
* Drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.

```{r, results='hide'}
str(training_data)
cleantraining <- training_data[, -which(names(training_data) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining <- cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance <- nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)

for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}

for(i in c(8:ncol(testing_data)-1)) {testing_data[,i] = as.numeric(as.character(testing_data[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.

featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[featureset]
featureset #now we have the model data built from our feature set.
```

## Model
* Split the sample in two sets. 75% for training and 25% for testing.
```{r}
idx <- createDataPartition(modeldata$classe, p=0.75, list=FALSE )
training <- modeldata[idx,]
testing <- modeldata[-idx,]
```
* A predictive model is fitted using Random Forest algorithm. Highly correlated variables were already removed but still this algorithm is robust to correlated covariates and outliers. 
* A 5 fold cross validation is used.
```{r}
control <- trainControl(method="cv", number = 5, allowParallel = TRUE)
model <- train(classe ~ ., data=training, method="rf", trControl=control, prof = TRUE, ntree = 250)
model
```
* The performance of the model is estimated on the validation data set.  
```{r}
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)

accuracy <- postResample(predict, testing$classe)
accuracy
```
* The estimated accuracy of the model is `r accuracy[1]*100`% and the estimated out of sample error is `r (1-accuracy[1])*100`%.

## Predictions
* The model is aplied to the original testing data.
```{r, results='hide'}
result <- predict(model, select(training, -classe))
result
```  

## Tree
```{r}
treeModel <- rpart(classe ~ ., data=cleantraining, method="class")
prp(treeModel) 
```

## ANSWERS
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

testing_data <- testing_data[featureset[featureset!='classe']]
answers <- predict(model, newdata=testing_data)
answers

pml_write_files(answers)
```
